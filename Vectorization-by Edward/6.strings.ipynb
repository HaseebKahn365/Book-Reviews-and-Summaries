{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57c3dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple' 'banadfsd32' 'cherry']\n",
      "40\n",
      "10\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "str_data = np.array([\"apple\", \"banadfsd324na\", \"cherry\"], dtype='U10') #utf-32 10 max chars\n",
    "\n",
    "bytes_data = np.array([\"apple\", \"banana\", \"cherry\"], dtype='S10') # ascii 1 byte\n",
    "\n",
    "obj_data = np.array([\"apple\", \"banana\", \"cherry\"], dtype=object)  #python string objects for words \n",
    "\n",
    "str_itemsize = str_data.itemsize\n",
    "bytes_itemsize = bytes_data.itemsize\n",
    "obj_itemsize = obj_data.itemsize\n",
    "\n",
    "print(str_data)\n",
    "print(str_itemsize)\n",
    "print(bytes_itemsize)\n",
    "print(obj_itemsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365de02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "legacy            object\n",
      "modern    string[python]\n",
      "dtype: object\n",
      "<class 'NoneType'>\n",
      "<class 'pandas._libs.missing.NAType'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "raw_data = [\"vector\", \"matrix\", None, \"tensor\"]\n",
    "\n",
    "df = pd.DataFrame({\"legacy\": raw_data})\n",
    "df[\"modern\"] = pd.Series(raw_data, dtype=\"string\")\n",
    "\n",
    "legacy_null = df.loc[2, \"legacy\"]\n",
    "modern_null = df.loc[2, \"modern\"]\n",
    "\n",
    "legacy_type = type(legacy_null)\n",
    "modern_type = type(modern_null)\n",
    "\n",
    "print(df.dtypes)\n",
    "print(legacy_type)\n",
    "print(modern_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b18f116b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vectorization' 'algorithm' 'machine_learning']\n",
      "[False  True False]\n",
      "[['user' '123']\n",
      " ['admin' '456']\n",
      " ['guest' '789']]\n",
      "user_123 | admin_456 | guest_789\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "arr = np.array([\"  vectorization  \", \"ALGORITHM\", \"Machine Learning\"], dtype=\"U\")\n",
    "\n",
    "stripped = np.char.strip(arr)\n",
    "lowered = np.char.lower(stripped)\n",
    "replaced = np.char.replace(lowered, \" \", \"_\")\n",
    "\n",
    "s = pd.Series([\"user_123\", \"admin_456\", \"guest_789\"], dtype=\"string\")\n",
    "\n",
    "contains_admin = s.str.contains(\"admin\")\n",
    "split_data = s.str.split(\"_\", expand=True)\n",
    "joined_data = s.str.cat(sep=\" | \")\n",
    "\n",
    "print(replaced)\n",
    "print(contains_admin.to_numpy())\n",
    "print(split_data.to_numpy())\n",
    "print(joined_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee58607",
   "metadata": {},
   "source": [
    "# Date formating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d6372a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2024-12-31' '2025-09-22' '2025-12-31']\n",
      "DatetimeIndex(['2024-12-31', '2025-09-22', '2025-12-31'], dtype='datetime64[ns]', freq=None)\n",
      "[2024 2025 2025]\n",
      "['December 31, 2024' 'September 22, 2025' 'December 31, 2025']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "today = pd.Timestamp.today()\n",
    "date_strings = [\n",
    "    (today - pd.Timedelta(days=365)).strftime(\"%Y-%m-%d\"),\n",
    "    (today - pd.Timedelta(days=100)).strftime(\"%Y-%m-%d\"),\n",
    "    today.strftime(\"%Y-%m-%d\")\n",
    "]\n",
    "\n",
    "np_dates = np.array(date_strings, dtype=\"datetime64[D]\")\n",
    "\n",
    "pd_dates = pd.to_datetime(date_strings)\n",
    "\n",
    "mixed_dates = pd.to_datetime(\n",
    "    [\"2025/12/31\", \"31-12-2025\", \"2025.12.31\"], \n",
    "    format=\"mixed\", \n",
    "    dayfirst=True\n",
    ")\n",
    "\n",
    "years = pd_dates.year\n",
    "months = pd_dates.month\n",
    "days = pd_dates.day\n",
    "\n",
    "formatted_strings = pd_dates.strftime(\"%B %d, %Y\")  # Remove .dt\n",
    "\n",
    "print(np_dates)\n",
    "print(pd_dates)\n",
    "print(years.to_numpy())\n",
    "print(formatted_strings.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd560709",
   "metadata": {},
   "source": [
    "# pandas categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dff3e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Size\n",
      "0  Medium\n",
      "1   Small\n",
      "2   Large\n",
      "3  Medium\n",
      "4   Small \n",
      "\n",
      "[1 0 2 1 0] \n",
      "\n",
      "['Small' 'Medium' 'Large'] \n",
      "\n",
      "     Size\n",
      "1   Small\n",
      "4   Small\n",
      "0  Medium\n",
      "3  Medium\n",
      "2   Large\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "raw_data = [\"Medium\", \"Small\", \"Large\", \"Medium\", \"Small\"]\n",
    "\n",
    "cat_series = pd.Series(raw_data, dtype=\"category\")\n",
    "\n",
    "ordered_cat = pd.Categorical(\n",
    "    raw_data, \n",
    "    categories=[\"Small\", \"Medium\", \"Large\"], \n",
    "    ordered=True\n",
    ")\n",
    "df = pd.DataFrame({\"Size\": ordered_cat})\n",
    "\n",
    "codes = df[\"Size\"].cat.codes\n",
    "categories = df[\"Size\"].cat.categories\n",
    "\n",
    "sorted_df = df.sort_values(by=\"Size\")\n",
    "\n",
    "print(df,\"\\n\")\n",
    "print(codes.to_numpy(),\"\\n\")\n",
    "print(categories.to_numpy(),\"\\n\")\n",
    "print(sorted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32249383",
   "metadata": {},
   "source": [
    "# Label Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44da2b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bird' 'cat' 'dog']\n",
      "[1 2 0 2 1]\n",
      "[2 1 2]\n",
      "['bird' 'cat' 'dog']\n",
      "{np.str_('bird'): np.int64(0), np.str_('cat'): np.int64(1), np.str_('dog'): np.int64(2)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train_labels = [\"cat\", \"dog\", \"bird\", \"dog\", \"cat\"]\n",
    "test_labels = [\"dog\", \"cat\", \"dog\"]\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(train_labels)\n",
    "\n",
    "train_encoded = encoder.transform(train_labels)\n",
    "test_encoded = encoder.transform(test_labels)\n",
    "\n",
    "original_labels = encoder.inverse_transform([0, 1, 2])\n",
    "\n",
    "mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
    "\n",
    "print(encoder.classes_)\n",
    "print(train_encoded)\n",
    "print(test_encoded)\n",
    "print(original_labels)\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d6de35",
   "metadata": {},
   "source": [
    "# Factorization Machine (FM) using a vectorized approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34d3181d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "[[5.18194409]\n",
      " [3.25882855]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def factorization_machine_layer(x, w0, w, v):\n",
    "    linear_terms = w0 + np.matmul(x, w)\n",
    "    \n",
    "    square_of_sum = np.square(np.matmul(x, v))\n",
    "    sum_of_square = np.matmul(np.square(x), np.square(v))\n",
    "    \n",
    "    interaction_terms = 0.5 * np.sum(square_of_sum - sum_of_square, axis=1, keepdims=True)\n",
    "    \n",
    "    return linear_terms + interaction_terms\n",
    "\n",
    "n_batch = 2\n",
    "n_features = 5\n",
    "k_factors = 3\n",
    "\n",
    "x = np.random.rand(n_batch, n_features)\n",
    "w0 = 0.5\n",
    "w = np.random.rand(n_features, 1)\n",
    "v = np.random.rand(n_features, k_factors)\n",
    "\n",
    "output = factorization_machine_layer(x, w0, w, v)\n",
    "\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8a6a91",
   "metadata": {},
   "source": [
    "# Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed5daa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False False]\n",
      "[[<NA>]\n",
      " [<NA>]\n",
      " [<NA>]\n",
      " ['150.50']]\n",
      "['Contact: admin@site.com, Cell: XXX-XXX-XXXX'\n",
      " 'Reach me at user.name123@domain.org'\n",
      " 'Invalid email: test@@com, Phone: XXX-XXX-XXXX'\n",
      " 'Price is $150.50 for 2 items']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "data = pd.Series([\n",
    "    \"Contact: admin@site.com, Cell: 555-123-4567\",\n",
    "    \"Reach me at user.name123@domain.org\",\n",
    "    \"Invalid email: test@@com, Phone: 123-456-7890\",\n",
    "    \"Price is $150.50 for 2 items\"\n",
    "], dtype=\"string\")\n",
    "\n",
    "email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "has_valid_email = data.str.contains(email_pattern, regex=True)\n",
    "\n",
    "prices = data.str.extract(r'\\$(\\d+\\.\\d+)')\n",
    "\n",
    "phone_pattern = r'\\d{3}-\\d{3}-\\d{4}'\n",
    "anonymized_data = data.str.replace(phone_pattern, \"XXX-XXX-XXXX\", regex=True)\n",
    "\n",
    "print(has_valid_email.to_numpy())\n",
    "print(prices.to_numpy())\n",
    "print(anonymized_data.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2839817a",
   "metadata": {},
   "source": [
    "# Serialize and deserialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3576ddee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[{\"id\": 101, \"name\": \"vector_processor\", \"active\": true}, {\"id\": 102, \"name\": \"matrix_engine\", \"active\": false}, {\"id\": 103, \"name\": \"tensor_core\", \"active\": true}]'\n",
      "True\n",
      "b'\\x80\\x05\\x95l\\x00\\x00\\x00\\x00\\x00\\x00\\x00]\\x94(}\\x94(\\x8c\\x02i'\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "records = [\n",
    "    {\"id\": 101, \"name\": \"vector_processor\", \"active\": True},\n",
    "    {\"id\": 102, \"name\": \"matrix_engine\", \"active\": False},\n",
    "    {\"id\": 103, \"name\": \"tensor_core\", \"active\": True}\n",
    "]\n",
    "\n",
    "json_string = json.dumps(records)\n",
    "json_bytes = json_string.encode(\"utf-8\")\n",
    "\n",
    "deserialized_json_string = json_bytes.decode(\"utf-8\")\n",
    "reconstructed_from_json = json.loads(deserialized_json_string)\n",
    "\n",
    "pickle_bytes = pickle.dumps(records)\n",
    "\n",
    "reconstructed_from_pickle = pickle.loads(pickle_bytes)\n",
    "\n",
    "print(json_bytes)\n",
    "print(reconstructed_from_json == records)\n",
    "print(pickle_bytes[:20])\n",
    "print(reconstructed_from_pickle == records)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
